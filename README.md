# 实现迷你版大模型：mini-mind
1.入门：参考Llama3模型结构，手动搭建一个小型大语言模型mini-mind（MHA多头注意力机制）。<br>
2.进阶：参考DeepSeek模型结构，构建我们的mini-deepseek（MoE混合专家结构，MLA多头潜在注意力机制，MTP多token预测），使用DPO进行强化学习微调。<br>
细节：分词器训练，模型预训练，微调，后训练的完整流程。<br>

参考：<br>
https://github.com/jingyaogong/minimind<br>
https://github.com/wyf3/llm_related<br>
